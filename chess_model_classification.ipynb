{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zarif123/SSLM-Project/blob/main/chess_model_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install python-chess"
      ],
      "metadata": {
        "id": "SmP4VhMQYNa3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OarbiURKBnK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a4ed8e-5f1f-4e89-acb6-ebcb031b8baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "folder = \"/content/gdrive/MyDrive/Statistical_LM_Group_Folder\"\n",
        "\n",
        "csv_file = \"chess_data_with_buckets.csv\"\n",
        "csv_path = f\"{folder}/{csv_file}\"\n",
        "\n",
        "\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%m_%d_%Y_%H_%M\")\n",
        "\n",
        "model_file = \"classifier_model.pth\"\n",
        "datetime = dt_string\n",
        "model_path = f\"{folder}/{datetime}_{model_file}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, get_linear_schedule_with_warmup\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "C7PY5j9_ZP99"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parameters"
      ],
      "metadata": {
        "id": "T4jiOnf42l76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "params = {\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 4,\n",
        "    \"learning_rate\": 0.00003,\n",
        "    \"warmup_steps\": 0.01,\n",
        "    \"accum_iter\": 16,\n",
        "    \"num_classes\": 6,\n",
        "    \"dropout\": 0.5\n",
        "}\n",
        "\n",
        "class Params:\n",
        "  def __init__(self, **kwargs):\n",
        "    for key, value in kwargs.items():\n",
        "      setattr(self, key, value)\n",
        "\n",
        "params = Params(**params)"
      ],
      "metadata": {
        "id": "ky6kpFpn0EF0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify Model"
      ],
      "metadata": {
        "id": "Ch3NE1cQ2p9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "  def __init__(self, dropout=params.dropout, num_classes=params.num_classes):\n",
        "    super(BertClassifier, self).__init__()\n",
        "\n",
        "    self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear = nn.Linear(768, num_classes)\n",
        "    # self.relu = nn.ReLU()\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, input_id, mask):\n",
        "    _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "    dropout_output = self.dropout(pooled_output)\n",
        "    linear_output = self.linear(dropout_output)\n",
        "    final_layer = self.softmax(linear_output)\n",
        "\n",
        "    return final_layer"
      ],
      "metadata": {
        "id": "lBPTBZJ9wXZw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Class"
      ],
      "metadata": {
        "id": "S0A41IRS2tFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChessDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, moves, labels):\n",
        "      tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "      self.labels = torch.Tensor(labels.values)\n",
        "      self.moves = [tokenizer(move, \n",
        "                              padding='max_length', max_length = 256, truncation=True,\n",
        "                              return_tensors=\"pt\") for move in moves]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return self.moves[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "jjod6hIlw0Xg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function"
      ],
      "metadata": {
        "id": "dr7lllaw2vMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer):\n",
        "    num_batches = len(train_dataloader)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = params.warmup_steps, num_training_steps = num_batches * params.epochs)\n",
        "    print(f\"Number of batches: {num_batches}\")\n",
        "    for epoch_num in range(params.epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for batch_idx, (train_input, train_label) in enumerate(train_dataloader):\n",
        "        #   print(sum(train_input['input_ids'].squeeze(1)[0] == 0))\n",
        "          train_label = train_label.to(device)\n",
        "          mask = train_input['attention_mask'].to(device)\n",
        "          input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "          output = model(input_id, mask)\n",
        "          \n",
        "          batch_loss = criterion(output, train_label.long())\n",
        "          total_loss_train += batch_loss.item()\n",
        "          \n",
        "          acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "          total_acc_train += acc\n",
        "\n",
        "          batch_loss.backward()\n",
        "\n",
        "          # Gradient Accumulation\n",
        "          if ((batch_idx + 1) % params.accum_iter == 0) or (batch_idx + 1 == num_batches):\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "          if batch_idx % 500 == 0:\n",
        "            print(f\"Batch Number: {batch_idx}\")\n",
        "            print(f\"Model Output: {torch.exp(output).tolist()}\")\n",
        "        \n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          for val_input, val_label in val_dataloader:\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_input['attention_mask'].to(device)\n",
        "            input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "            \n",
        "            batch_loss = criterion(output, val_label.long())\n",
        "            total_loss_val += batch_loss.item()\n",
        "            \n",
        "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "            total_acc_val += acc\n",
        "        \n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataloader): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_dataloader) / params.batch_size: .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_dataloader): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_dataloader) / params.batch_size: .3f}')\n",
        "        \n",
        "        torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "x337jZ5ixgPG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Function"
      ],
      "metadata": {
        "id": "Zj8L6NoCNVxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_dataloader):\n",
        "  total_acc_test = 0\n",
        "  with torch.no_grad():\n",
        "    for test_input, test_label in test_dataloader:\n",
        "      test_label = test_label.to(device)\n",
        "      mask = test_input['attention_mask'].to(device)\n",
        "      input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      output = model(input_id, mask)\n",
        "      # print(f\"Model Output: {torch.exp(output).tolist()}\")\n",
        "      # print(f\"Prediction: {output.argmax(dim=1).tolist()}, Truth: {test_label.tolist()}\")\n",
        "\n",
        "      acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "      total_acc_test += acc\n",
        "       \n",
        "    print(f\"Test Accuracy: {total_acc_test / len(test_dataloader): .3f}\")"
      ],
      "metadata": {
        "id": "ullCZNUINYYj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "1MoqFHld3kHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "chess_data = pd.read_csv(csv_path)\n",
        "X = chess_data[\"Moves\"]\n",
        "y = chess_data[\"Bucket\"]\n",
        "\n",
        "balancer = RandomUnderSampler()\n",
        "X = X.values.reshape(-1, 1)\n",
        "X, y = balancer.fit_resample(X, y)\n",
        "rating_counts = y.value_counts().sort_index()\n",
        "X = X.flatten()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, shuffle=True) # Splits into train/test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, shuffle=True) # Splits train into train/val"
      ],
      "metadata": {
        "id": "Fb7ZFYfU3nPY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = ChessDataset(X_train, y_train), ChessDataset(X_val, y_val), ChessDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "ykScPcfAxGtF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoFWB2KvkTNe",
        "outputId": "b499c1d9-8d09-4a90-9f63-06db5238aed2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4208\n",
              "1    4208\n",
              "2    4208\n",
              "3    4208\n",
              "4    4208\n",
              "5    4208\n",
              "Name: Bucket, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=params.batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=params.batch_size)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data)"
      ],
      "metadata": {
        "id": "tVa8WpZc6Axi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Model"
      ],
      "metadata": {
        "id": "k05I66qnvMeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# train_model_name = \"06_01_2023_20_16_classifier_model.pth\"\n",
        "# train_model_path = f\"{folder}/{train_model_name}\"\n",
        "\n",
        "model = BertClassifier()\n",
        "model = model.to(device)\n",
        "# model.load_state_dict(torch.load(train_model_path))\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr = params.learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLMfD4iz5aWl",
        "outputId": "b94f6abb-5b5e-402d-94b7-e7e3eca38605"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Training"
      ],
      "metadata": {
        "id": "mChdv51O8dC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHj36RRX8e0y",
        "outputId": "2ba869cc-64f7-436c-82c7-25da2ae964ab"
      },
      "execution_count": 42,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 1894\n",
            "Batch Number: 0\n",
            "Model Output: [[0.11375552415847778, 0.27257442474365234, 0.13157206773757935, 0.11397063732147217, 0.2116733342409134, 0.15645404160022736], [0.11153519153594971, 0.12825696170330048, 0.12467087805271149, 0.09536059945821762, 0.44292309880256653, 0.09725327044725418], [0.0669088214635849, 0.22532737255096436, 0.06686806678771973, 0.12256550043821335, 0.32513514161109924, 0.1931951493024826], [0.06267055124044418, 0.20295967161655426, 0.1921083778142929, 0.05906037986278534, 0.2995136082172394, 0.1836874634027481], [0.1916622668504715, 0.14140872657299042, 0.1461545079946518, 0.1434008777141571, 0.22786016762256622, 0.14951348304748535], [0.10266309231519699, 0.20363864302635193, 0.07972744107246399, 0.08867200464010239, 0.326962947845459, 0.19833582639694214], [0.09448019415140152, 0.10995162278413773, 0.12315820902585983, 0.11799319088459015, 0.35311752557754517, 0.20129923522472382], [0.13163964450359344, 0.2233724296092987, 0.20617814362049103, 0.10140717774629593, 0.25525254011154175, 0.08215007930994034]]\n",
            "Batch Number: 500\n",
            "Model Output: [[0.14973962306976318, 0.128130242228508, 0.2198072075843811, 0.14900684356689453, 0.1752668023109436, 0.17804937064647675], [0.16405914723873138, 0.1633642613887787, 0.17762236297130585, 0.1884072870016098, 0.13287004828453064, 0.17367686331272125], [0.14285780489444733, 0.12193174660205841, 0.21898721158504486, 0.15951964259147644, 0.13026122748851776, 0.226442351937294], [0.12718553841114044, 0.17525644600391388, 0.14367835223674774, 0.15901757776737213, 0.23090630769729614, 0.16395579278469086], [0.14933553338050842, 0.11805335432291031, 0.18122191727161407, 0.17021112143993378, 0.24804699420928955, 0.13313111662864685], [0.11393075436353683, 0.16243812441825867, 0.13141004741191864, 0.19107721745967865, 0.19133657217025757, 0.20980726182460785], [0.13128909468650818, 0.1702493280172348, 0.13445550203323364, 0.16880442202091217, 0.2161250114440918, 0.179076686501503], [0.15800414979457855, 0.14880962669849396, 0.2269435077905655, 0.10702776163816452, 0.20558272302150726, 0.1536322385072708]]\n",
            "Batch Number: 1000\n",
            "Model Output: [[0.15484890341758728, 0.12923744320869446, 0.15754148364067078, 0.14204806089401245, 0.29503893852233887, 0.12128515541553497], [0.11975276470184326, 0.1355307251214981, 0.21262948215007782, 0.15316250920295715, 0.2641943097114563, 0.11473024636507034], [0.18020518124103546, 0.1083461120724678, 0.1966255009174347, 0.14053206145763397, 0.20783372223377228, 0.1664573699235916], [0.25111648440361023, 0.2080570012331009, 0.15422244369983673, 0.09581811726093292, 0.1408262699842453, 0.14995965361595154], [0.12265916913747787, 0.12107976526021957, 0.17480146884918213, 0.18400107324123383, 0.21601849794387817, 0.1814400851726532], [0.136254221200943, 0.1390562802553177, 0.1448422074317932, 0.18114733695983887, 0.2668103575706482, 0.13188955187797546], [0.16999505460262299, 0.15099646151065826, 0.18023274838924408, 0.11997940391302109, 0.2232700139284134, 0.15552635490894318], [0.06821798533201218, 0.07144500315189362, 0.2592543065547943, 0.18504005670547485, 0.27518782019615173, 0.1408548206090927]]\n",
            "Batch Number: 1500\n",
            "Model Output: [[0.19941574335098267, 0.1643521934747696, 0.2576338052749634, 0.19535666704177856, 0.0958230271935463, 0.08741844445466995], [0.45682820677757263, 0.23430803418159485, 0.12132445722818375, 0.0916767418384552, 0.06090514361858368, 0.03495744243264198], [0.3460937738418579, 0.17205014824867249, 0.1775655895471573, 0.16346631944179535, 0.09507748484611511, 0.04574669525027275], [0.3117375671863556, 0.17899025976657867, 0.20550061762332916, 0.12339769303798676, 0.0976119339466095, 0.0827619805932045], [0.13711923360824585, 0.1327747255563736, 0.21145477890968323, 0.22324541211128235, 0.17685569822788239, 0.11855015903711319], [0.05778993293642998, 0.09068771451711655, 0.11974072456359863, 0.17217838764190674, 0.2240222692489624, 0.3355809152126312], [0.1613570749759674, 0.14941872656345367, 0.19759155809879303, 0.19520696997642517, 0.1586189568042755, 0.13780678808689117], [0.3466576039791107, 0.26799383759498596, 0.21073035895824432, 0.05686768516898155, 0.06361092627048492, 0.05413958802819252]]\n",
            "Epochs: 1 | Train Loss:  1.754             | Train Accuracy:  0.218             | Val Loss:  1.727             | Val Accuracy:  0.243\n",
            "Batch Number: 0\n",
            "Model Output: [[0.32549989223480225, 0.2818577289581299, 0.17612072825431824, 0.09870939701795578, 0.06868606805801392, 0.04912619665265083], [0.3214624524116516, 0.36339297890663147, 0.14950451254844666, 0.05813007801771164, 0.07403957098722458, 0.03347037732601166], [0.22723886370658875, 0.20963473618030548, 0.2538423240184784, 0.11456945538520813, 0.13531869649887085, 0.05939597636461258], [0.267326295375824, 0.261393666267395, 0.15001076459884644, 0.15575332939624786, 0.10362014174461365, 0.061895836144685745], [0.07202403247356415, 0.1257740557193756, 0.14284680783748627, 0.16707977652549744, 0.2372557818889618, 0.2550196051597595], [0.16106173396110535, 0.17628638446331024, 0.19795015454292297, 0.15689603984355927, 0.19453947246074677, 0.11326621472835541], [0.3149263262748718, 0.2898603081703186, 0.2076987624168396, 0.08779780566692352, 0.06933961808681488, 0.030377034097909927], [0.19663846492767334, 0.2550138831138611, 0.2070431262254715, 0.11847268790006638, 0.14514127373695374, 0.07769054174423218]]\n",
            "Batch Number: 500\n",
            "Model Output: [[0.21797581017017365, 0.22292973101139069, 0.2249036282300949, 0.17291775345802307, 0.07769355922937393, 0.08357960730791092], [0.240994393825531, 0.2359563559293747, 0.16792625188827515, 0.1237940639257431, 0.11209133267402649, 0.11923764646053314], [0.38318151235580444, 0.24482910335063934, 0.1914111077785492, 0.08500736951828003, 0.05588293820619583, 0.039687976241111755], [0.14869654178619385, 0.20853041112422943, 0.1957245171070099, 0.19079157710075378, 0.09696483612060547, 0.15929217636585236], [0.3864334523677826, 0.23782840371131897, 0.24794380366802216, 0.04752190038561821, 0.057006191462278366, 0.023266155272722244], [0.02032422460615635, 0.07904429733753204, 0.0816524550318718, 0.14391881227493286, 0.35119810700416565, 0.32386213541030884], [0.08277630805969238, 0.22368338704109192, 0.17477792501449585, 0.16985085606575012, 0.14170658588409424, 0.20720486342906952], [0.0654919371008873, 0.19035686552524567, 0.22497208416461945, 0.16638486087322235, 0.19427470862865448, 0.1585194617509842]]\n",
            "Batch Number: 1000\n",
            "Model Output: [[0.06749127805233002, 0.12733449041843414, 0.17354963719844818, 0.20249198377132416, 0.2416103184223175, 0.1875222623348236], [0.0830964744091034, 0.16799664497375488, 0.14338132739067078, 0.19965101778507233, 0.21283969283103943, 0.19303488731384277], [0.19599692523479462, 0.23145943880081177, 0.21160049736499786, 0.14073534309864044, 0.1530248373746872, 0.0671829953789711], [0.010157146491110325, 0.032975051552057266, 0.10834047943353653, 0.14395831525325775, 0.3600154519081116, 0.34455356001853943], [0.167930006980896, 0.2831619381904602, 0.1721600443124771, 0.1414693295955658, 0.15897737443447113, 0.07630130648612976], [0.04570186883211136, 0.08354280143976212, 0.12258367985486984, 0.1638093888759613, 0.2744073271751404, 0.30995485186576843], [0.028133973479270935, 0.06929245591163635, 0.16983211040496826, 0.1779680699110031, 0.24005000293254852, 0.31472334265708923], [0.09308110922574997, 0.1594584435224533, 0.19029828906059265, 0.20030249655246735, 0.19512049853801727, 0.16173923015594482]]\n",
            "Batch Number: 1500\n",
            "Model Output: [[0.41928598284721375, 0.3432261049747467, 0.13834276795387268, 0.041028235107660294, 0.03763782978057861, 0.02047910913825035], [0.25623252987861633, 0.2217341512441635, 0.2267320454120636, 0.14533337950706482, 0.08358778804540634, 0.0663800984621048], [0.25619640946388245, 0.3353649377822876, 0.1849742978811264, 0.10624505579471588, 0.07404257357120514, 0.04317673668265343], [0.5307141542434692, 0.27756214141845703, 0.1120973452925682, 0.027987565845251083, 0.03453627601265907, 0.0171024352312088], [0.3577747046947479, 0.34634754061698914, 0.14839871227741241, 0.06439045071601868, 0.044038452208042145, 0.03905004262924194], [0.4300267994403839, 0.40217727422714233, 0.09949560463428497, 0.03372635319828987, 0.020983869209885597, 0.013590099290013313], [0.054872557520866394, 0.09854649007320404, 0.17220762372016907, 0.2065611183643341, 0.1838662028312683, 0.28394603729248047], [0.19210873544216156, 0.26742225885391235, 0.1856188029050827, 0.1706680804491043, 0.10909672826528549, 0.07508548349142075]]\n",
            "Epochs: 2 | Train Loss:  1.619             | Train Accuracy:  0.288             | Val Loss:  1.648             | Val Accuracy:  0.284\n",
            "Batch Number: 0\n",
            "Model Output: [[0.19623133540153503, 0.2165922075510025, 0.24196407198905945, 0.139775812625885, 0.09581811726093292, 0.10961852222681046], [0.397306352853775, 0.321155846118927, 0.17324890196323395, 0.05385143682360649, 0.024220122024416924, 0.030217325314879417], [0.4128987789154053, 0.2314353585243225, 0.2216682732105255, 0.08163505792617798, 0.024653909727931023, 0.02770868130028248], [0.1259584128856659, 0.20377832651138306, 0.19976653158664703, 0.185057133436203, 0.14530497789382935, 0.14013457298278809], [0.102862648665905, 0.13846080005168915, 0.20196321606636047, 0.1936056762933731, 0.1573297679424286, 0.20577789843082428], [0.35691332817077637, 0.30045613646507263, 0.15074659883975983, 0.10339270532131195, 0.04703250899910927, 0.04145868867635727], [0.5213384628295898, 0.21153566241264343, 0.17425067722797394, 0.05138925835490227, 0.021692346781492233, 0.019793637096881866], [0.3394930362701416, 0.22395259141921997, 0.17338886857032776, 0.14870242774486542, 0.06677499413490295, 0.047688134014606476]]\n",
            "Batch Number: 500\n",
            "Model Output: [[0.1871616095304489, 0.24128217995166779, 0.24454188346862793, 0.16731932759284973, 0.0724179670214653, 0.08727706968784332], [0.01042967289686203, 0.024842604994773865, 0.07975813001394272, 0.23029473423957825, 0.23627173900604248, 0.41840314865112305], [0.11703167110681534, 0.21730934083461761, 0.23830708861351013, 0.16583497822284698, 0.16018912196159363, 0.10132776200771332], [0.10778718441724777, 0.25865447521209717, 0.22273722290992737, 0.20456531643867493, 0.11785157769918442, 0.08840419352054596], [0.010339142754673958, 0.023785879835486412, 0.06958946585655212, 0.21444949507713318, 0.24193355441093445, 0.4399024546146393], [0.14414943754673004, 0.1904243677854538, 0.22626373171806335, 0.21590293943881989, 0.11988132447004318, 0.10337816923856735], [0.42598050832748413, 0.3042232096195221, 0.1474885791540146, 0.06446585059165955, 0.0326634906232357, 0.02517840825021267], [0.08608771860599518, 0.19902488589286804, 0.2371051162481308, 0.20734283328056335, 0.1470721960067749, 0.12336722016334534]]\n",
            "Batch Number: 1000\n",
            "Model Output: [[0.13368311524391174, 0.2075609713792801, 0.23909823596477509, 0.20583303272724152, 0.10056410729885101, 0.11326051503419876], [0.010954763740301132, 0.027018314227461815, 0.07849019020795822, 0.17582200467586517, 0.3371948003768921, 0.3705199956893921], [0.014643913134932518, 0.03614715486764908, 0.11962170898914337, 0.16592557728290558, 0.22272129356861115, 0.4409404397010803], [0.02007579617202282, 0.045518048107624054, 0.09980582445859909, 0.16443942487239838, 0.2625439167022705, 0.4076169431209564], [0.02521882951259613, 0.05002334341406822, 0.11416716128587723, 0.20387385785579681, 0.2669844925403595, 0.33973225951194763], [0.029785335063934326, 0.06858056038618088, 0.13932907581329346, 0.22812671959400177, 0.23932653665542603, 0.29485175013542175], [0.06676623970270157, 0.09561532735824585, 0.154628723859787, 0.21714724600315094, 0.19657546281814575, 0.2692669928073883], [0.10139144212007523, 0.15441979467868805, 0.22416481375694275, 0.19279704988002777, 0.17640089988708496, 0.15082605183124542]]\n",
            "Batch Number: 1500\n",
            "Model Output: [[0.02691267617046833, 0.049859460443258286, 0.1395556777715683, 0.20448999106884003, 0.29364028573036194, 0.28554192185401917], [0.0965842679142952, 0.15190616250038147, 0.2208605855703354, 0.23438188433647156, 0.14704632759094238, 0.1492207646369934], [0.11726917326450348, 0.21289728581905365, 0.20180276036262512, 0.18310585618019104, 0.1677914559841156, 0.11713342368602753], [0.06792361289262772, 0.11502768844366074, 0.206024169921875, 0.2039562314748764, 0.20892152190208435, 0.19814682006835938], [0.04981615021824837, 0.09026108682155609, 0.15483126044273376, 0.22155697643756866, 0.22823195159435272, 0.2553025782108307], [0.22192764282226562, 0.3255382776260376, 0.22111938893795013, 0.1341911107301712, 0.05832578241825104, 0.038897909224033356], [0.01611275225877762, 0.03837667405605316, 0.12258689105510712, 0.18902862071990967, 0.3389127254486084, 0.2949824333190918], [0.006778984796255827, 0.02021818980574608, 0.07345400005578995, 0.15291491150856018, 0.3936106264591217, 0.3530232608318329]]\n",
            "Epochs: 3 | Train Loss:  1.573             | Train Accuracy:  0.306             | Val Loss:  1.546             | Val Accuracy:  0.306\n",
            "Batch Number: 0\n",
            "Model Output: [[0.02629794180393219, 0.07656009495258331, 0.20298179984092712, 0.20756228268146515, 0.2827354967594147, 0.20386233925819397], [0.02778712287545204, 0.06897014379501343, 0.2019709199666977, 0.24207034707069397, 0.21783502399921417, 0.2413664609193802], [0.05665431171655655, 0.08978653699159622, 0.18045616149902344, 0.24348942935466766, 0.24897193908691406, 0.18064150214195251], [0.02113923244178295, 0.050590429455041885, 0.20148096978664398, 0.1985660195350647, 0.2482098937034607, 0.28001338243484497], [0.3729894161224365, 0.34851598739624023, 0.148233100771904, 0.0830126404762268, 0.024736503139138222, 0.022512320429086685], [0.10064343363046646, 0.17404405772686005, 0.23926423490047455, 0.21731963753700256, 0.14810915291309357, 0.12061955034732819], [0.3355202078819275, 0.2956148386001587, 0.18936657905578613, 0.10214392840862274, 0.04899032786488533, 0.028364082798361778], [0.31842827796936035, 0.27637842297554016, 0.18365779519081116, 0.10021485388278961, 0.06677604466676712, 0.0545445941388607]]\n",
            "Batch Number: 500\n",
            "Model Output: [[0.06295302510261536, 0.12849704921245575, 0.2309570610523224, 0.23467865586280823, 0.17850621044635773, 0.16440802812576294], [0.04192262515425682, 0.0957176461815834, 0.18790504336357117, 0.24311299622058868, 0.22191007435321808, 0.20943155884742737], [0.2713549733161926, 0.3683522343635559, 0.1839340627193451, 0.0998285710811615, 0.04976039007306099, 0.02676972560584545], [0.2584514915943146, 0.2770940661430359, 0.30049553513526917, 0.09767578542232513, 0.04065874591469765, 0.02562437579035759], [0.0369209386408329, 0.09712383151054382, 0.1512267142534256, 0.26455405354499817, 0.2029118537902832, 0.24726256728172302], [0.2060530185699463, 0.2595152258872986, 0.1805654615163803, 0.22521066665649414, 0.07082110643386841, 0.0578344389796257], [0.07421397417783737, 0.15176232159137726, 0.2185474932193756, 0.2772068977355957, 0.1504620611667633, 0.12780722975730896], [0.05515690892934799, 0.10272496938705444, 0.16515877842903137, 0.29514238238334656, 0.17499183118343353, 0.2068251073360443]]\n",
            "Batch Number: 1000\n",
            "Model Output: [[0.0779760554432869, 0.22945904731750488, 0.2527827322483063, 0.2203325778245926, 0.12211620062589645, 0.09733331948518753], [0.12752559781074524, 0.2277085781097412, 0.2967537045478821, 0.18348678946495056, 0.10218430310487747, 0.06234108656644821], [0.19491055607795715, 0.2715925872325897, 0.22779957950115204, 0.16876375675201416, 0.09394001960754395, 0.04299353063106537], [0.35077497363090515, 0.31714877486228943, 0.2226480096578598, 0.07468854635953903, 0.020969456061720848, 0.013770261779427528], [0.09801126271486282, 0.154727965593338, 0.23751118779182434, 0.21939441561698914, 0.1864333301782608, 0.10392183065414429], [0.20993025600910187, 0.3474177122116089, 0.22523370385169983, 0.11731665581464767, 0.06432215124368668, 0.035779524594545364], [0.03146105632185936, 0.05468019098043442, 0.13606709241867065, 0.2721938192844391, 0.23736105859279633, 0.26823681592941284], [0.24511605501174927, 0.272294282913208, 0.24626268446445465, 0.14115065336227417, 0.06176409125328064, 0.03341218829154968]]\n",
            "Batch Number: 1500\n",
            "Model Output: [[0.11032818257808685, 0.25384390354156494, 0.3004002273082733, 0.19871418178081512, 0.08562515676021576, 0.051088251173496246], [0.06691102683544159, 0.15113317966461182, 0.21749667823314667, 0.23121042549610138, 0.20597432553768158, 0.1272743046283722], [0.029845671728253365, 0.05468343570828438, 0.17551498115062714, 0.24233852326869965, 0.25860750675201416, 0.23900984227657318], [0.14370189607143402, 0.23299595713615417, 0.3305787146091461, 0.15980231761932373, 0.08315300196409225, 0.049768079072237015], [0.21103258430957794, 0.2676103413105011, 0.24892747402191162, 0.1453038901090622, 0.07796601951122284, 0.04915959760546684], [0.006955045275390148, 0.02058292180299759, 0.08401328325271606, 0.14116713404655457, 0.28560253977775574, 0.4616791009902954], [0.3684614598751068, 0.35266897082328796, 0.19086717069149017, 0.047057028859853745, 0.027869999408721924, 0.013075324706733227], [0.410919189453125, 0.3336552679538727, 0.14410898089408875, 0.06387918442487717, 0.033662259578704834, 0.013775081373751163]]\n",
            "Epochs: 4 | Train Loss:  1.521             | Train Accuracy:  0.329             | Val Loss:  1.537             | Val Accuracy:  0.328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Testing"
      ],
      "metadata": {
        "id": "wH3GOh7rvQTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_model_name = \"06_02_2023_09_01_classifier_model.pth\"\n",
        "# test_model_path = f\"{folder}/{test_model_name}\"\n",
        "\n",
        "test_model = BertClassifier()\n",
        "test_model = test_model.to(device)\n",
        "test_model.load_state_dict(torch.load(model_path))\n",
        "test(test_model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HSMDah7SZpM",
        "outputId": "bdfe4a66-1698-455d-be5b-1888786f7719"
      },
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.321\n"
          ]
        }
      ]
    }
  ]
}